{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_app.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbguPbdRs6PN"
      },
      "source": [
        "\n",
        "## Embedding + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "L_w-2b7Us6Pn",
        "outputId": "082ece71-bdbe-49c3-801f-bc525befe831"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, display, SVG\n",
        "from IPython.core import display as ICD\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.regularizers import L1L2\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "init_notebook_mode(connected=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABGYRqPes6Ps"
      },
      "source": [
        "def batch_generator_shuffle(X_data, y_data, batch_size):\n",
        "    samples_per_epoch = X_data.shape[0]\n",
        "    number_of_batches = samples_per_epoch/batch_size\n",
        "    counter=0\n",
        "    index = np.arange(np.shape(y_data)[0])\n",
        "    np.random.shuffle(index)\n",
        "    while 1:\n",
        "        index_batch = index[batch_size*counter:batch_size*(counter+1)]\n",
        "        X_batch = X_data[index_batch,:]\n",
        "        y_batch = y_data[index_batch]\n",
        "        counter += 1\n",
        "        yield X_batch,y_batch\n",
        "        if (counter > number_of_batches):\n",
        "            np.random.shuffle(index)\n",
        "            counter=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcNx6faLs6Ps"
      },
      "source": [
        "### Initialize objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlC9gy1ps6Pt"
      },
      "source": [
        "seed = 8\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "le = LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ1i-iTds6Pq"
      },
      "source": [
        "###Using ROC AUC as metric in Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiV-eyzys6Pr"
      },
      "source": [
        "def as_keras_metric(method):\n",
        "    import functools\n",
        "    from keras import backend as K\n",
        "    import tensorflow as tf\n",
        "    @functools.wraps(method)\n",
        "    def wrapper(self, args, **kwargs):\n",
        "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
        "        value, update_op = method(self, args, **kwargs)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([update_op]):\n",
        "            value = tf.identity(value)\n",
        "        return value\n",
        "    return wrapper\n",
        "\n",
        "@as_keras_metric\n",
        "def auc_pr(y_true, y_pred, curve='PR'):\n",
        "    return tf.metrics.auc(y_true, y_pred, curve=curve)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY9nEJJps6Pt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bztVf8UIs6Pt"
      },
      "source": [
        "### Read train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsfFwZBSs6Pu"
      },
      "source": [
        "train_data = pd.read_csv('train.csv', encoding='ISO-8859-1')\n",
        "test_data = pd.read_csv('test.csv', encoding='utf8')\n",
        "test_data = test_data[test_data.columns[1:-1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "dxixJhPos6Pu",
        "outputId": "4446dd0e-506b-4bf6-b443-017c7ea7b178"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Source</th>\n",
              "      <th>Host</th>\n",
              "      <th>Link</th>\n",
              "      <th>Date(ET)</th>\n",
              "      <th>Time(ET)</th>\n",
              "      <th>time(GMT)</th>\n",
              "      <th>Title</th>\n",
              "      <th>TRANS_CONV_TEXT</th>\n",
              "      <th>Patient_Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FORUMS</td>\n",
              "      <td>cafepharma.com</td>\n",
              "      <td>http://cafepharma.com/boards/threads/epstein.5...</td>\n",
              "      <td>6/15/2016</td>\n",
              "      <td>13:58:00</td>\n",
              "      <td>6/15/2016 23:28</td>\n",
              "      <td>Epstein</td>\n",
              "      <td>I don't disagree with you in principle. I'm ju...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FORUMS</td>\n",
              "      <td>www.patient.co.uk</td>\n",
              "      <td>http://www.patient.co.uk/forums/discuss/enlarg...</td>\n",
              "      <td>5/7/2016</td>\n",
              "      <td>0.820833333</td>\n",
              "      <td>42498.21667</td>\n",
              "      <td>Enlarged Heart.Thread Enlarged Heart</td>\n",
              "      <td>I am always dizzy I get dizzy standing up so I...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BLOG</td>\n",
              "      <td>http://abcnewsradioonline.com/entertainment-news</td>\n",
              "      <td>http://abcnewsradioonline.com/entertainment-ne...</td>\n",
              "      <td>4/14/2016</td>\n",
              "      <td>15:00:38</td>\n",
              "      <td>4/15/2016 0:30</td>\n",
              "      <td>Queen Latifah Joins American Heart Association...</td>\n",
              "      <td>Axelle/Bauer-Griffin/FilmMagic(NEW YORK) -- Qu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FORUMS</td>\n",
              "      <td>www.cancer-forums.net</td>\n",
              "      <td>http://www.cancer-forums.net/viewtopic.php?f=1...</td>\n",
              "      <td>6/18/2016</td>\n",
              "      <td>20:46:00</td>\n",
              "      <td>6/19/2016 6:16</td>\n",
              "      <td>Bulaemia</td>\n",
              "      <td>I am 17 and I have been throwing up for about ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FORUMS</td>\n",
              "      <td>www.diyaudio.com</td>\n",
              "      <td>http://www.diyaudio.com/forums/lounge/292252-d...</td>\n",
              "      <td>6/15/2016</td>\n",
              "      <td>3:26:00</td>\n",
              "      <td>6/15/2016 12:56</td>\n",
              "      <td>DIY Silver interconnects and RCAs???</td>\n",
              "      <td>Quote: Originally Posted by Boyan Silyavski Wa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Source  ... Patient_Tag\n",
              "0  FORUMS  ...           0\n",
              "1  FORUMS  ...           1\n",
              "2    BLOG  ...           0\n",
              "3  FORUMS  ...           1\n",
              "4  FORUMS  ...           0\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_U3rg11s6Pv"
      },
      "source": [
        "### Using only 'TRANS_CONV_TEXT' column for predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s3RxSMWs6Pv"
      },
      "source": [
        "train_data = train_data[train_data['TRANS_CONV_TEXT'].notnull()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7UDfOv5s6Pv"
      },
      "source": [
        "### Imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffkun-ERs6Pw",
        "outputId": "2940119c-a10f-4639-9d53-c5360a294abe"
      },
      "source": [
        "train_data['Patient_Tag'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.792388\n",
              "1    0.207612\n",
              "Name: Patient_Tag, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuZMDSvHs6Pw"
      },
      "source": [
        "X_train = train_data['TRANS_CONV_TEXT']\n",
        "Y_train = train_data['Patient_Tag']\n",
        "Y_train = to_categorical(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8fceAiks6Pw"
      },
      "source": [
        "### Preprocess text\n",
        "- Remove punctuations from data.\n",
        "- Apply lemmatization on words. Convert each word to its lemma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_sOxBL-SHQE",
        "outputId": "e219536d-3782-4dbf-bd84-4acc192ef412"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H86puqZs6Px"
      },
      "source": [
        "def preprocess_data(X_train, stemmer, lemma):\n",
        "    preprocessed_data = []\n",
        "    trans = str.maketrans('/(){}', ' ' * 5)\n",
        "    trans_punc = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    for text in X_train:\n",
        "        text = text.lower().translate(trans)\n",
        "        text = text.translate(trans_punc)\n",
        "        text = [lemma.lemmatize(word) for word in text.split()]\n",
        "        preprocessed_data.append(' '.join(text))\n",
        "\n",
        "    return preprocessed_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTMvLZ80s6Px"
      },
      "source": [
        "preprocessed_data = preprocess_data(X_train, stemmer, lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_hBdmxWs6Px",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "ded95a5b-97dd-4a62-bb8a-fad400bbb6ac"
      },
      "source": [
        "preprocessed_data[-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i went through a sleep study ahi severe at 95 and titration test in late 2011 but wa never able to sleep effectively i own the system one series 50 650 bipap pro that i wa prescribed and an opus 360 nasal pillow assembly both are essentially unused im about 20 pound lighter than i wa back then and my sleeping seems to be a little bit better now than it wa back then whats the best way of trying to address my sleep apnea again is it ok to just try my existing machine and setting and adjust using sleepyhead do i need to go back to the doc and or do another sleep study are there any particularly good mask since 2011 that might be better than what i have ive spent the last three week dealing with a father with congestive heart failure and id like to try and do what i can to avoid that'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lQjVUyZs6Py"
      },
      "source": [
        "### Initialize variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7gvHi97s6Pz"
      },
      "source": [
        "number_of_words = len(t.word_index) + 1\n",
        "max_length_of_input = 1000\n",
        "embedding_vector_length = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUdwQNhWs6Py"
      },
      "source": [
        "### Tokenize text\n",
        "- Tokenize text and convert them into integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njotbRmOs6Py"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(preprocessed_data)\n",
        "encoded_lines = t.texts_to_sequences(preprocessed_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8jITvOfs6Pz"
      },
      "source": [
        "### Pad sequences to same length and split data to form validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBdWhMjes6Pz"
      },
      "source": [
        "X_train = sequence.pad_sequences(encoded_lines, max_length_of_input)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.33, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sGmGFqNs6Pz"
      },
      "source": [
        "### Create an LSTM network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfmW0nsds6P0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(number_of_words, embedding_vector_length, input_length = max_length_of_input))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(3, activation = 'softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvQzfCZ9s6P0"
      },
      "source": [
        "### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BSoiCxMWw6R"
      },
      "source": [
        "import numpy as np \n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekbIj5jYs6P0"
      },
      "source": [
        "precision = as_keras_metric(tf.metrics.Precision)\n",
        "recall = as_keras_metric(tf.metrics.Recall)\n",
        "\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[auc, 'accuracy'])\n",
        "\n",
        "mc = keras.callbacks.ModelCheckpoint('weights{epoch:02d}.h5', \n",
        "                                     save_weights_only=True, save_freq=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LTe2Lo4WkqO",
        "outputId": "eb55f2da-0383-4fd1-8742-13056777e932"
      },
      "source": [
        "mc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.ModelCheckpoint at 0x7f9c5f98eb10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXCP9MamV8Xq"
      },
      "source": [
        "model.fit_generator(generator=batch_generator_shuffle(X_train, y_train, 32), epochs=5, validation_data=(X_valid, y_valid),\n",
        "                               steps_per_epoch=X_train.shape[0] / 32, \n",
        "                    callbacks=[mc])\n",
        "\n",
        "scores = model.evaluate(X_valid, y_valid)\n",
        "print ('\\n')\n",
        "print (scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWHVWNS-s6P5"
      },
      "source": [
        "### Preprocess test data and convert into vector form "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpo2ojxVs6P6"
      },
      "source": [
        "X_test = test_data['TRANS_CONV_TEXT']\n",
        "X_test = preprocess_data(X_test, stemmer, lemma)\n",
        "X_test = t.texts_to_sequences(X_test)\n",
        "X_test = sequence.pad_sequences(X_test, max_length_of_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVq3M41Qs6P6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33418fe-d9ad-4820-ea93-acbf70146c3f"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(571, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0cfsZ1Ws6P7"
      },
      "source": [
        "### Predict output and save predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_siAv9wIs6P8"
      },
      "source": [
        "output = model.predict(X_test, 32)\n",
        "\n",
        "patient_tag = np.argmax(output, axis=1)\n",
        "index = list(range(1, len(output)+1))\n",
        "test_data_df = pd.DataFrame({'Index': index,'Patient_Tag': patient_tag}).set_index('Index')\n",
        "test_data_df.Patient_Tag = test_data_df.Patient_Tag.astype('int')\n",
        "test_data_df.to_csv('LSTM_approach.csv', columns=['Patient_Tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MonRY0c9s6P8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "9da06d91-799a-4c87-bb5c-a64a9ac0a331"
      },
      "source": [
        "test_data_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient_Tag</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Index</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Patient_Tag\n",
              "Index             \n",
              "1                1\n",
              "2                1\n",
              "3                0\n",
              "4                0\n",
              "5                0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnT8FN2YjHTy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}